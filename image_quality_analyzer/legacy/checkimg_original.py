#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ch∆∞∆°ng tr√¨nh so s√°nh ch·∫•t l∆∞·ª£ng ·∫£nh chuy√™n nghi·ªáp
ƒê√°nh gi√° ·∫£nh ch·ª•p t·ª´ ƒëi·ªán tho·∫°i v·ªõi t·∫•t c·∫£ c√°c ti√™u ch√≠ c√≥ th·ªÉ
Author: AI Assistant
Date: July 12, 2025
"""

import cv2
import numpy as np
import os
import sys
from PIL import Image, ImageStat, ExifTags
import matplotlib.pyplot as plt
from scipy import ndimage
from skimage import measure, filters, feature, metrics
from skimage.restoration import estimate_sigma
import math
from typing import Tuple, Dict, Any
import warnings
warnings.filterwarnings('ignore')

class ImageQualityAnalyzer:
    """L·ªõp ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng ·∫£nh chuy√™n nghi·ªáp"""
    
    def __init__(self):
        self.results = {}
        
    def load_image(self, image_path: str) -> Tuple[np.ndarray, Image.Image]:
        """T·∫£i ·∫£nh v√† chuy·ªÉn ƒë·ªïi ƒë·ªãnh d·∫°ng"""
        try:
            # T·∫£i b·∫±ng OpenCV
            img_cv = cv2.imread(image_path)
            if img_cv is None:
                raise ValueError(f"Kh√¥ng th·ªÉ t·∫£i ·∫£nh: {image_path}")
            img_cv = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)
            
            # T·∫£i b·∫±ng PIL ƒë·ªÉ l·∫•y EXIF
            img_pil = Image.open(image_path)
            
            return img_cv, img_pil
        except Exception as e:
            print(f"L·ªói khi t·∫£i ·∫£nh {image_path}: {e}")
            return None, None
    
    def get_basic_info(self, img_cv: np.ndarray, img_pil: Image.Image) -> Dict[str, Any]:
        """L·∫•y th√¥ng tin c∆° b·∫£n v√† EXIF c·ªßa ·∫£nh"""
        height, width = img_cv.shape[:2]
        channels = img_cv.shape[2] if len(img_cv.shape) > 2 else 1
        
        # T√≠nh megapixels
        megapixels = (width * height) / 1000000
        
        # T√≠nh t·ª∑ l·ªá khung h√¨nh
        aspect_ratio = width / height
        
        # L·∫•y th√¥ng tin EXIF chi ti·∫øt
        exif_data = {}
        camera_info = {}
        
        if hasattr(img_pil, '_getexif') and img_pil._getexif():
            exif = img_pil._getexif()
            for tag, value in exif.items():
                tag_name = ExifTags.TAGS.get(tag, tag)
                exif_data[tag_name] = value
                
                # Tr√≠ch xu·∫•t th√¥ng tin camera quan tr·ªçng
                if tag_name == 'Make':
                    camera_info['camera_make'] = str(value)
                elif tag_name == 'Model':
                    camera_info['camera_model'] = str(value)
                elif tag_name == 'FNumber':
                    camera_info['aperture'] = f"f/{float(value):.1f}"
                elif tag_name == 'ExposureTime':
                    if isinstance(value, tuple):
                        camera_info['shutter_speed'] = f"{value[0]}/{value[1]}s"
                    else:
                        camera_info['shutter_speed'] = f"{value}s"
                elif tag_name == 'ISOSpeedRatings':
                    camera_info['iso'] = value
                elif tag_name == 'FocalLength':
                    if isinstance(value, tuple):
                        camera_info['focal_length'] = f"{float(value[0]/value[1]):.1f}mm"
                    else:
                        camera_info['focal_length'] = f"{float(value):.1f}mm"
                elif tag_name == 'WhiteBalance':
                    camera_info['white_balance'] = 'Auto' if value == 0 else 'Manual'
                elif tag_name == 'Flash':
                    camera_info['flash'] = 'On' if value & 1 else 'Off'
                elif tag_name == 'ExposureMode':
                    modes = ['Auto', 'Manual', 'Auto bracket']
                    camera_info['exposure_mode'] = modes[value] if value < len(modes) else 'Unknown'
                elif tag_name == 'MeteringMode':
                    modes = ['Unknown', 'Average', 'Center-weighted', 'Spot', 'Multi-spot', 'Pattern', 'Partial']
                    camera_info['metering_mode'] = modes[value] if value < len(modes) else 'Unknown'
                elif tag_name == 'DateTime':
                    camera_info['date_time'] = str(value)
                elif tag_name == 'ColorSpace':
                    camera_info['color_space'] = 'sRGB' if value == 1 else 'Adobe RGB'
        
        # T√≠nh DPI n·∫øu c√≥
        dpi_info = {}
        if hasattr(img_pil, 'info') and 'dpi' in img_pil.info:
            dpi_info['dpi'] = img_pil.info['dpi']
        
        return {
            'width': width,
            'height': height,
            'channels': channels,
            'megapixels': round(megapixels, 2),
            'aspect_ratio': round(aspect_ratio, 2),
            'file_size': os.path.getsize(img_pil.filename) if hasattr(img_pil, 'filename') else 0,
            'camera_info': camera_info,
            'dpi_info': dpi_info,
            'exif_data': exif_data
        }
    
    def calculate_sharpness(self, img_cv: np.ndarray) -> Dict[str, float]:
        """T√≠nh ƒë·ªô s·∫Øc n√©t c·ªßa ·∫£nh"""
        gray = cv2.cvtColor(img_cv, cv2.COLOR_RGB2GRAY)
        
        # Laplacian variance (ph∆∞∆°ng ph√°p chu·∫©n)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        
        # Sobel variance
        sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        sobel_var = np.sqrt(sobel_x**2 + sobel_y**2).var()
        
        # Brenner gradient
        brenner = np.sum((gray[2:, :] - gray[:-2, :])**2)
        
        # Tenengrad
        tenengrad = np.sum(sobel_x**2 + sobel_y**2)
        
        return {
            'laplacian_variance': round(laplacian_var, 2),
            'sobel_variance': round(sobel_var, 2),
            'brenner_gradient': round(brenner, 2),
            'tenengrad': round(tenengrad, 2)
        }
    
    def calculate_noise(self, img_cv: np.ndarray) -> Dict[str, float]:
        """T√≠nh m·ª©c ƒë·ªô nhi·ªÖu c·ªßa ·∫£nh"""
        gray = cv2.cvtColor(img_cv, cv2.COLOR_RGB2GRAY)
        
        # ∆Ø·ªõc t√≠nh sigma noise b·∫±ng ph∆∞∆°ng ph√°p Laplacian
        laplacian = cv2.Laplacian(gray, cv2.CV_64F)
        sigma = np.sqrt(np.mean(laplacian**2)) / 6.0  # H·ªá s·ªë 6 cho ph√¢n ph·ªëi Laplacian
        
        # SNR (Signal-to-Noise Ratio)
        signal_power = np.mean(gray**2)
        noise_power = sigma**2
        snr = 10 * np.log10(signal_power / noise_power) if noise_power > 0 else float('inf')
        
        # PSNR peak signal-to-noise ratio
        mse = np.mean((gray - np.mean(gray))**2)
        psnr = 20 * np.log10(255 / np.sqrt(mse)) if mse > 0 else float('inf')
        
        # Th√™m ph∆∞∆°ng ph√°p ∆∞·ªõc t√≠nh nhi·ªÖu kh√°c
        # Robust median estimator
        median_filter = cv2.medianBlur(gray, 5)
        noise_estimate = np.median(np.abs(gray - median_filter)) * 1.4826
        
        return {
            'noise_sigma': round(sigma, 4),
            'noise_estimate': round(noise_estimate, 4),
            'snr_db': round(snr, 2),
            'psnr_db': round(psnr, 2)
        }
    
    def calculate_brightness_contrast(self, img_cv: np.ndarray) -> Dict[str, float]:
        """T√≠nh ƒë·ªô s√°ng v√† ƒë·ªô t∆∞∆°ng ph·∫£n"""
        gray = cv2.cvtColor(img_cv, cv2.COLOR_RGB2GRAY)
        
        # ƒê·ªô s√°ng trung b√¨nh
        brightness = np.mean(gray)
        
        # ƒê·ªô t∆∞∆°ng ph·∫£n RMS
        contrast_rms = np.sqrt(np.mean((gray - brightness)**2))
        
        # ƒê·ªô t∆∞∆°ng ph·∫£n Michelson
        max_val = np.max(gray)
        min_val = np.min(gray)
        michelson_contrast = (max_val - min_val) / (max_val + min_val) if (max_val + min_val) > 0 else 0
        
        # Histogram analysis
        hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
        hist_norm = hist.ravel() / hist.sum()
        
        # Entropy
        entropy = -np.sum(hist_norm * np.log2(hist_norm + 1e-7))
        
        return {
            'brightness': round(brightness, 2),
            'contrast_rms': round(contrast_rms, 2),
            'michelson_contrast': round(michelson_contrast, 4),
            'entropy': round(entropy, 2)
        }
    
    def calculate_color_quality(self, img_cv: np.ndarray) -> Dict[str, float]:
        """T√≠nh ch·∫•t l∆∞·ª£ng m√†u s·∫Øc"""
        # Chuy·ªÉn sang HSV
        hsv = cv2.cvtColor(img_cv, cv2.COLOR_RGB2HSV)
        
        # ƒê·ªô b√£o h√≤a trung b√¨nh
        saturation_mean = np.mean(hsv[:,:,1])
        saturation_std = np.std(hsv[:,:,1])
        
        # ƒê·ªô r·ª±c r·ª° m√†u s·∫Øc
        vibrance = np.mean(np.max(img_cv, axis=2) - np.min(img_cv, axis=2))
        
        # Color cast detection
        r_mean = np.mean(img_cv[:,:,0])
        g_mean = np.mean(img_cv[:,:,1])
        b_mean = np.mean(img_cv[:,:,2])
        
        color_cast = np.std([r_mean, g_mean, b_mean])
        
        # Gamut coverage (∆∞·ªõc t√≠nh)
        unique_colors = len(np.unique(img_cv.reshape(-1, 3), axis=0))
        gamut_coverage = unique_colors / (img_cv.shape[0] * img_cv.shape[1])
        
        return {
            'saturation_mean': round(saturation_mean, 2),
            'saturation_std': round(saturation_std, 2),
            'vibrance': round(vibrance, 2),
            'color_cast': round(color_cast, 2),
            'gamut_coverage': round(gamut_coverage, 4),
            'unique_colors': unique_colors
        }
    
    def calculate_exposure(self, img_cv: np.ndarray) -> Dict[str, float]:
        """T√≠nh ch·∫•t l∆∞·ª£ng ph∆°i s√°ng"""
        gray = cv2.cvtColor(img_cv, cv2.COLOR_RGB2GRAY)
        
        # Histogram analysis
        hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
        hist_norm = hist.ravel() / hist.sum()
        
        # Underexposure (pixels < 5% of max)
        underexposed = np.sum(hist_norm[:13])  # 0-12 (5% of 255)
        
        # Overexposure (pixels > 95% of max)
        overexposed = np.sum(hist_norm[242:])  # 242-255 (95% of 255)
        
        # Well-exposed (middle range)
        well_exposed = np.sum(hist_norm[51:204])  # 20%-80% range
        
        # Dynamic range
        dynamic_range = np.max(gray) - np.min(gray)
        
        return {
            'underexposed_ratio': round(underexposed, 4),
            'overexposed_ratio': round(overexposed, 4),
            'well_exposed_ratio': round(well_exposed, 4),
            'dynamic_range': round(dynamic_range, 2)
        }
    
    def calculate_composition(self, img_cv: np.ndarray) -> Dict[str, float]:
        """T√≠nh ch·∫•t l∆∞·ª£ng b·ªë c·ª•c"""
        gray = cv2.cvtColor(img_cv, cv2.COLOR_RGB2GRAY)
        h, w = gray.shape
        
        # Rule of thirds
        # Chia ·∫£nh th√†nh 9 ph·∫ßn v√† t√≠nh ƒë·ªô c√¢n b·∫±ng
        third_h, third_w = h // 3, w // 3
        
        regions = []
        for i in range(3):
            for j in range(3):
                region = gray[i*third_h:(i+1)*third_h, j*third_w:(j+1)*third_w]
                regions.append(np.mean(region))
        
        # T√≠nh ƒë·ªô c√¢n b·∫±ng
        balance = 1 - (np.std(regions) / np.mean(regions))
        
        # Edge density
        edges = feature.canny(gray, sigma=1)
        edge_density = np.sum(edges) / (h * w)
        
        # Symmetry analysis
        left_half = gray[:, :w//2]
        right_half = np.fliplr(gray[:, w//2:])
        min_width = min(left_half.shape[1], right_half.shape[1])
        symmetry = np.corrcoef(left_half[:, :min_width].flatten(), 
                              right_half[:, :min_width].flatten())[0, 1]
        
        return {
            'composition_balance': round(balance, 4),
            'edge_density': round(edge_density, 6),
            'symmetry': round(symmetry, 4) if not np.isnan(symmetry) else 0
        }
    
    def calculate_depth_of_field(self, img_cv: np.ndarray, camera_info: Dict) -> Dict[str, Any]:
        """T√≠nh to√°n ƒë·ªô s√¢u tr∆∞·ªùng ·∫£nh v√† bokeh"""
        gray = cv2.cvtColor(img_cv, cv2.COLOR_RGB2GRAY)
        
        # Ph√¢n t√≠ch ƒë·ªô m·ªù n·ªÅn (bokeh quality)
        # S·ª≠ d·ª•ng gradient ƒë·ªÉ t√¨m v√πng n√©t v√† m·ªù
        sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)
        
        # T√≠nh to√°n ƒë·ªô s√¢u tr∆∞·ªùng ·∫£nh
        h, w = gray.shape
        center_region = gray[h//4:3*h//4, w//4:3*w//4]
        edge_region = np.concatenate([
            gray[:h//4, :].flatten(),
            gray[3*h//4:, :].flatten(),
            gray[:, :w//4].flatten(),
            gray[:, 3*w//4:].flatten()
        ])
        
        center_sharpness = np.var(center_region)
        edge_sharpness = np.var(edge_region)
        dof_ratio = center_sharpness / (edge_sharpness + 1e-6)
        
        # Ph√¢n t√≠ch bokeh
        # T√¨m c√°c v√πng m·ªù c√≥ ƒë·ªô t∆∞∆°ng ph·∫£n th·∫•p
        blur_kernel = cv2.GaussianBlur(gray, (15, 15), 0)
        blur_diff = np.abs(gray.astype(float) - blur_kernel.astype(float))
        bokeh_quality = np.mean(blur_diff)
        
        # T√≠nh to√°n focus peaking
        focus_mask = gradient_magnitude > np.percentile(gradient_magnitude, 80)
        focus_percentage = np.sum(focus_mask) / (h * w) * 100
        
        # ∆Ø·ªõc t√≠nh kh·∫©u ƒë·ªô t·ª´ ƒë·ªô m·ªù n·ªÅn
        estimated_aperture = None
        if 'aperture' in camera_info:
            estimated_aperture = camera_info['aperture']
        
        return {
            'dof_ratio': round(dof_ratio, 2),
            'bokeh_quality': round(bokeh_quality, 2),
            'focus_percentage': round(focus_percentage, 2),
            'estimated_aperture': estimated_aperture,
            'center_sharpness': round(center_sharpness, 2),
            'edge_sharpness': round(edge_sharpness, 2)
        }
    
    def calculate_color_science(self, img_cv: np.ndarray) -> Dict[str, float]:
        """Ph√¢n t√≠ch khoa h·ªçc m√†u s·∫Øc chuy√™n nghi·ªáp"""
        # Chuy·ªÉn sang c√°c kh√¥ng gian m√†u kh√°c nhau
        hsv = cv2.cvtColor(img_cv, cv2.COLOR_RGB2HSV)
        lab = cv2.cvtColor(img_cv, cv2.COLOR_RGB2LAB)
        yuv = cv2.cvtColor(img_cv, cv2.COLOR_RGB2YUV)
        
        # Ph√¢n t√≠ch Lab color space
        l_channel = lab[:, :, 0]  # Lightness
        a_channel = lab[:, :, 1]  # Green-Red
        b_channel = lab[:, :, 2]  # Blue-Yellow
        
        # T√≠nh to√°n Color Temperature (∆∞·ªõc t√≠nh)
        r_mean = np.mean(img_cv[:, :, 0])
        g_mean = np.mean(img_cv[:, :, 1])
        b_mean = np.mean(img_cv[:, :, 2])
        
        # ∆Ø·ªõc t√≠nh color temperature t·ª´ RGB ratio
        if b_mean > 0:
            color_temp_ratio = r_mean / b_mean
            estimated_color_temp = 5500 - (color_temp_ratio - 1) * 1000
            estimated_color_temp = max(2000, min(10000, estimated_color_temp))
        else:
            estimated_color_temp = 5500
        
        # T√≠nh to√°n Tint
        tint = (g_mean - (r_mean + b_mean) / 2) / 255 * 100
        
        # Ph√¢n t√≠ch Color Grading
        shadows = np.mean(img_cv[img_cv < 85])
        midtones = np.mean(img_cv[(img_cv >= 85) & (img_cv < 170)])
        highlights = np.mean(img_cv[img_cv >= 170])
        
        # T√≠nh to√°n Color Harmony
        hue_values = hsv[:, :, 0].flatten()
        hue_hist = np.histogram(hue_values, bins=36, range=(0, 180))[0]
        dominant_hues = np.argsort(hue_hist)[-3:]  # Top 3 dominant hues
        
        # Color Contrast trong Lab space
        a_contrast = np.std(a_channel)
        b_contrast = np.std(b_channel)
        
        # Skin tone analysis (n·∫øu c√≥)
        skin_tone_quality = self.analyze_skin_tones(img_cv)
        
        return {
            'estimated_color_temp': round(estimated_color_temp, 0),
            'tint': round(tint, 2),
            'shadows_avg': round(shadows, 2),
            'midtones_avg': round(midtones, 2),
            'highlights_avg': round(highlights, 2),
            'lab_a_contrast': round(a_contrast, 2),
            'lab_b_contrast': round(b_contrast, 2),
            'dominant_hues': dominant_hues.tolist(),
            'skin_tone_quality': skin_tone_quality
        }
    
    def analyze_skin_tones(self, img_cv: np.ndarray) -> Dict[str, float]:
        """Ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng skin tone"""
        # Chuy·ªÉn sang YCrCb ƒë·ªÉ ph√°t hi·ªán da
        ycrcb = cv2.cvtColor(img_cv, cv2.COLOR_RGB2YCrCb)
        
        # Skin tone detection trong YCrCb
        lower_skin = np.array([0, 133, 77], dtype=np.uint8)
        upper_skin = np.array([255, 173, 127], dtype=np.uint8)
        skin_mask = cv2.inRange(ycrcb, lower_skin, upper_skin)
        
        skin_percentage = np.sum(skin_mask > 0) / (img_cv.shape[0] * img_cv.shape[1]) * 100
        
        if skin_percentage > 1:  # C√≥ skin tone
            # Ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng skin tone
            skin_pixels = img_cv[skin_mask > 0]
            if len(skin_pixels) > 0:
                skin_r = np.mean(skin_pixels[:, 0])
                skin_g = np.mean(skin_pixels[:, 1])
                skin_b = np.mean(skin_pixels[:, 2])
                
                # T√≠nh to√°n skin tone naturalness
                skin_ratio_rg = skin_r / (skin_g + 1e-6)
                skin_ratio_rb = skin_r / (skin_b + 1e-6)
                
                # Ideal skin tone ratios
                ideal_rg = 1.15
                ideal_rb = 1.2
                
                naturalness = 100 - abs(skin_ratio_rg - ideal_rg) * 50 - abs(skin_ratio_rb - ideal_rb) * 50
                naturalness = max(0, min(100, naturalness))
                
                return {
                    'skin_percentage': round(skin_percentage, 2),
                    'skin_naturalness': round(naturalness, 2),
                    'skin_r_avg': round(skin_r, 2),
                    'skin_g_avg': round(skin_g, 2),
                    'skin_b_avg': round(skin_b, 2)
                }
        
        return {
            'skin_percentage': round(skin_percentage, 2),
            'skin_naturalness': 0,
            'skin_r_avg': 0,
            'skin_g_avg': 0,
            'skin_b_avg': 0
        }
    
    def calculate_professional_metrics(self, img_cv: np.ndarray) -> Dict[str, float]:
        """T√≠nh to√°n c√°c ch·ªâ s·ªë chuy√™n nghi·ªáp"""
        gray = cv2.cvtColor(img_cv, cv2.COLOR_RGB2GRAY)
        
        # T√≠nh to√°n MTF (Modulation Transfer Function)
        # S·ª≠ d·ª•ng edge response ƒë·ªÉ ∆∞·ªõc t√≠nh MTF
        edges = cv2.Canny(gray, 50, 150)
        edge_response = np.sum(edges) / (gray.shape[0] * gray.shape[1])
        
        # T√≠nh to√°n Chromatic Aberration
        r_channel = img_cv[:, :, 0]
        g_channel = img_cv[:, :, 1]
        b_channel = img_cv[:, :, 2]
        
        # T√≠nh correlation gi·ªØa c√°c channel
        rg_correlation = np.corrcoef(r_channel.flatten(), g_channel.flatten())[0, 1]
        rb_correlation = np.corrcoef(r_channel.flatten(), b_channel.flatten())[0, 1]
        gb_correlation = np.corrcoef(g_channel.flatten(), b_channel.flatten())[0, 1]
        
        chromatic_aberration = 100 - np.mean([rg_correlation, rb_correlation, gb_correlation]) * 100
        
        # T√≠nh to√°n Vignetting
        h, w = gray.shape
        center = (h // 2, w // 2)
        
        # T·∫°o mask h√¨nh tr√≤n t·ª´ center
        Y, X = np.ogrid[:h, :w]
        center_mask = (X - center[1]) ** 2 + (Y - center[0]) ** 2 <= (min(h, w) // 4) ** 2
        edge_mask = (X - center[1]) ** 2 + (Y - center[0]) ** 2 >= (min(h, w) // 3) ** 2
        
        center_brightness = np.mean(gray[center_mask])
        edge_brightness = np.mean(gray[edge_mask])
        
        vignetting = (center_brightness - edge_brightness) / center_brightness * 100
        
        # T√≠nh to√°n Distortion (barrel/pincushion)
        # S·ª≠ d·ª•ng grid analysis
        distortion_score = self.calculate_distortion(gray)
        
        # T√≠nh to√°n Noise pattern analysis
        noise_pattern = self.analyze_noise_pattern(gray)
        
        return {
            'mtf_estimate': round(edge_response * 1000, 2),
            'chromatic_aberration': round(chromatic_aberration, 2),
            'vignetting': round(vignetting, 2),
            'distortion_score': round(distortion_score, 2),
            'noise_pattern': noise_pattern
        }
    
    def calculate_distortion(self, gray: np.ndarray) -> float:
        """T√≠nh to√°n distortion"""
        h, w = gray.shape
        
        # T√¨m edges
        edges = cv2.Canny(gray, 50, 150)
        
        # T√¨m lines
        lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)
        
        if lines is not None:
            # Ph√¢n t√≠ch ƒë·ªô cong c·ªßa c√°c ƒë∆∞·ªùng th·∫≥ng
            line_angles = []
            for line in lines:
                rho, theta = line[0]
                line_angles.append(theta)
            
            # T√≠nh ƒë·ªô l·ªách chu·∫©n c·ªßa c√°c g√≥c
            angle_std = np.std(line_angles)
            distortion = angle_std * 180 / np.pi
            return min(distortion, 10)  # Cap at 10 degrees
        
        return 0
    
    def analyze_noise_pattern(self, gray: np.ndarray) -> Dict[str, float]:
        """Ph√¢n t√≠ch pattern nhi·ªÖu"""
        # High frequency analysis
        f_transform = np.fft.fft2(gray)
        f_shift = np.fft.fftshift(f_transform)
        magnitude_spectrum = np.log(np.abs(f_shift) + 1)
        
        # T√≠nh to√°n noise characteristics
        h, w = gray.shape
        center = (h // 2, w // 2)
        
        # High frequency noise
        high_freq_mask = np.zeros((h, w))
        cv2.circle(high_freq_mask, center, min(h, w) // 4, 1, -1)
        high_freq_noise = np.mean(magnitude_spectrum[high_freq_mask == 0])
        
        # Banding analysis
        row_variance = np.var(np.mean(gray, axis=1))
        col_variance = np.var(np.mean(gray, axis=0))
        banding_score = (row_variance + col_variance) / 2
        
        return {
            'high_freq_noise': round(high_freq_noise, 2),
            'banding_score': round(banding_score, 2),
            'row_variance': round(row_variance, 2),
            'col_variance': round(col_variance, 2)
        }
    
    def calculate_overall_score(self, analysis: Dict[str, Any]) -> float:
        """T√≠nh ƒëi·ªÉm t·ªïng k·∫øt chung v·ªõi nhi·ªÅu ti√™u ch√≠ h∆°n"""
        scores = {}
        
        # ƒêi·ªÉm ƒë·ªô s·∫Øc n√©t (0-100)
        sharpness_score = min(100, analysis['sharpness']['laplacian_variance'] / 10)
        scores['sharpness'] = sharpness_score
        
        # ƒêi·ªÉm nhi·ªÖu (0-100, c√†ng √≠t nhi·ªÖu c√†ng t·ªët)
        noise_score = min(100, max(0, analysis['noise']['snr_db'] - 10) * 2)
        scores['noise'] = noise_score
        
        # ƒêi·ªÉm ƒë·ªô t∆∞∆°ng ph·∫£n (0-100)
        contrast_score = min(100, analysis['brightness_contrast']['contrast_rms'] / 2)
        scores['contrast'] = contrast_score
        
        # ƒêi·ªÉm m√†u s·∫Øc (0-100)
        color_score = min(100, analysis['color']['saturation_mean'] / 2.55)
        scores['color'] = color_score
        
        # ƒêi·ªÉm ph∆°i s√°ng (0-100)
        exposure_score = analysis['exposure']['well_exposed_ratio'] * 100
        scores['exposure'] = exposure_score
        
        # ƒêi·ªÉm b·ªë c·ª•c (0-100)
        composition_score = analysis['composition']['composition_balance'] * 100
        scores['composition'] = composition_score
        
        # ƒêi·ªÉm ƒë·ªô s√¢u tr∆∞·ªùng ·∫£nh (0-100)
        dof_score = min(100, analysis['depth_of_field']['bokeh_quality'] / 2)
        scores['depth_of_field'] = dof_score
        
        # ƒêi·ªÉm khoa h·ªçc m√†u s·∫Øc (0-100)
        color_science_score = min(100, analysis['color_science']['skin_tone_quality']['skin_naturalness'])
        scores['color_science'] = color_science_score
        
        # ƒêi·ªÉm chuy√™n nghi·ªáp (0-100)
        professional_score = 100 - min(50, analysis['professional_metrics']['chromatic_aberration'])
        scores['professional'] = professional_score
        
        # ƒêi·ªÉm t·ªïng (tr·ªçng s·ªë c·∫≠p nh·∫≠t)
        weights = {
            'sharpness': 0.20,
            'noise': 0.15,
            'contrast': 0.12,
            'color': 0.12,
            'exposure': 0.12,
            'composition': 0.08,
            'depth_of_field': 0.08,
            'color_science': 0.08,
            'professional': 0.05
        }
        
        total_score = sum(scores[key] * weights[key] for key in scores)
        
        return {
            'individual_scores': scores,
            'total_score': round(total_score, 2),
            'grade': self.get_grade(total_score)
        }
    
    def get_grade(self, score: float) -> str:
        """Chuy·ªÉn ƒëi·ªÉm th√†nh x·∫øp h·∫°ng"""
        if score >= 90:
            return "Xu·∫•t s·∫Øc (A+)"
        elif score >= 80:
            return "T·ªët (A)"
        elif score >= 70:
            return "Kh√° (B+)"
        elif score >= 60:
            return "Trung b√¨nh kh√° (B)"
        elif score >= 50:
            return "Trung b√¨nh (C)"
        else:
            return "C·∫ßn c·∫£i thi·ªán (D)"
    
    def analyze_image(self, image_path: str) -> Dict[str, Any]:
        """Ph√¢n t√≠ch to√†n di·ªán m·ªôt ·∫£nh"""
        print(f"\nüîç ƒêang ph√¢n t√≠ch ·∫£nh: {os.path.basename(image_path)}")
        
        img_cv, img_pil = self.load_image(image_path)
        if img_cv is None:
            return None
        
        analysis = {}
        
        # Th√¥ng tin c∆° b·∫£n
        analysis['basic_info'] = self.get_basic_info(img_cv, img_pil)
        
        # ƒê·ªô s·∫Øc n√©t
        analysis['sharpness'] = self.calculate_sharpness(img_cv)
        
        # Nhi·ªÖu
        analysis['noise'] = self.calculate_noise(img_cv)
        
        # ƒê·ªô s√°ng v√† t∆∞∆°ng ph·∫£n
        analysis['brightness_contrast'] = self.calculate_brightness_contrast(img_cv)
        
        # Ch·∫•t l∆∞·ª£ng m√†u s·∫Øc
        analysis['color'] = self.calculate_color_quality(img_cv)
        
        # Ph∆°i s√°ng
        analysis['exposure'] = self.calculate_exposure(img_cv)
        
        # B·ªë c·ª•c
        analysis['composition'] = self.calculate_composition(img_cv)
        
        # ƒê·ªô s√¢u tr∆∞·ªùng ·∫£nh v√† bokeh
        analysis['depth_of_field'] = self.calculate_depth_of_field(img_cv, analysis['basic_info']['camera_info'])
        
        # Khoa h·ªçc m√†u s·∫Øc
        analysis['color_science'] = self.calculate_color_science(img_cv)
        
        # Ch·ªâ s·ªë chuy√™n nghi·ªáp
        analysis['professional_metrics'] = self.calculate_professional_metrics(img_cv)
        
        # ƒêi·ªÉm t·ªïng k·∫øt
        analysis['overall_score'] = self.calculate_overall_score(analysis)
        
        return analysis
    
    def compare_images(self, image1_path: str, image2_path: str):
        """So s√°nh hai ·∫£nh v√† ƒë∆∞a ra k·∫øt lu·∫≠n"""
        print("=" * 80)
        print("üñºÔ∏è  CH∆Ø∆†NG TR√åNH SO S√ÅNH CH·∫§T L∆Ø·ª¢NG ·∫¢NH CHUY√äN NGHI·ªÜP")
        print("=" * 80)
        
        # Ph√¢n t√≠ch ·∫£nh 1
        analysis1 = self.analyze_image(image1_path)
        if analysis1 is None:
            return
        
        # Ph√¢n t√≠ch ·∫£nh 2
        analysis2 = self.analyze_image(image2_path)
        if analysis2 is None:
            return
        
        # In k·∫øt qu·∫£ chi ti·∫øt
        self.print_detailed_results(image1_path, analysis1, image2_path, analysis2)
        
        # In k·∫øt qu·∫£ so s√°nh
        self.print_comparison_results(image1_path, analysis1, image2_path, analysis2)
    
    def print_detailed_results(self, img1_path: str, analysis1: Dict, img2_path: str, analysis2: Dict):
        """In k·∫øt qu·∫£ chi ti·∫øt cho t·ª´ng ·∫£nh"""
        
        for i, (path, analysis) in enumerate([(img1_path, analysis1), (img2_path, analysis2)], 1):
            print(f"\nüìä K·∫æT QU·∫¢ PH√ÇN T√çCH CHI TI·∫æT - ·∫¢NH {i}: {os.path.basename(path)}")
            print("-" * 70)
            
            # Th√¥ng tin c∆° b·∫£n
            basic = analysis['basic_info']
            camera = basic['camera_info']
            print(f"üìê Th√¥ng tin c∆° b·∫£n:")
            print(f"   ‚Ä¢ K√≠ch th∆∞·ªõc: {basic['width']}x{basic['height']} ({basic['megapixels']} MP)")
            print(f"   ‚Ä¢ T·ª∑ l·ªá khung h√¨nh: {basic['aspect_ratio']}")
            print(f"   ‚Ä¢ K√™nh m√†u: {basic['channels']}")
            print(f"   ‚Ä¢ K√≠ch th∆∞·ªõc file: {basic['file_size'] / 1024:.1f} KB")
            
            # Th√¥ng tin camera
            if camera:
                print(f"\nüì∑ Th√¥ng tin camera:")
                if 'camera_make' in camera:
                    print(f"   ‚Ä¢ H√£ng: {camera['camera_make']}")
                if 'camera_model' in camera:
                    print(f"   ‚Ä¢ Model: {camera['camera_model']}")
                if 'aperture' in camera:
                    print(f"   ‚Ä¢ Kh·∫©u ƒë·ªô: {camera['aperture']}")
                if 'shutter_speed' in camera:
                    print(f"   ‚Ä¢ T·ªëc ƒë·ªô m√†n tr·∫≠p: {camera['shutter_speed']}")
                if 'iso' in camera:
                    print(f"   ‚Ä¢ ISO: {camera['iso']}")
                if 'focal_length' in camera:
                    print(f"   ‚Ä¢ Ti√™u c·ª±: {camera['focal_length']}")
                if 'white_balance' in camera:
                    print(f"   ‚Ä¢ White Balance: {camera['white_balance']}")
                if 'flash' in camera:
                    print(f"   ‚Ä¢ Flash: {camera['flash']}")
                if 'exposure_mode' in camera:
                    print(f"   ‚Ä¢ Ch·∫ø ƒë·ªô ph∆°i s√°ng: {camera['exposure_mode']}")
                if 'metering_mode' in camera:
                    print(f"   ‚Ä¢ Ch·∫ø ƒë·ªô ƒëo s√°ng: {camera['metering_mode']}")
                if 'color_space' in camera:
                    print(f"   ‚Ä¢ Kh√¥ng gian m√†u: {camera['color_space']}")
            
            # ƒê·ªô s·∫Øc n√©t
            sharpness = analysis['sharpness']
            print(f"\nüîç ƒê·ªô s·∫Øc n√©t:")
            print(f"   ‚Ä¢ Laplacian Variance: {sharpness['laplacian_variance']}")
            print(f"   ‚Ä¢ Sobel Variance: {sharpness['sobel_variance']}")
            print(f"   ‚Ä¢ Brenner Gradient: {sharpness['brenner_gradient']}")
            print(f"   ‚Ä¢ Tenengrad: {sharpness['tenengrad']}")
            
            # Nhi·ªÖu
            noise = analysis['noise']
            print(f"\nüì° Ch·∫•t l∆∞·ª£ng t√≠n hi·ªáu:")
            print(f"   ‚Ä¢ M·ª©c nhi·ªÖu (Laplacian): {noise['noise_sigma']}")
            print(f"   ‚Ä¢ M·ª©c nhi·ªÖu (Median): {noise['noise_estimate']}")
            print(f"   ‚Ä¢ SNR: {noise['snr_db']} dB")
            print(f"   ‚Ä¢ PSNR: {noise['psnr_db']} dB")
            
            # ƒê·ªô s√°ng v√† t∆∞∆°ng ph·∫£n
            brightness = analysis['brightness_contrast']
            print(f"\nüí° ƒê·ªô s√°ng & T∆∞∆°ng ph·∫£n:")
            print(f"   ‚Ä¢ ƒê·ªô s√°ng trung b√¨nh: {brightness['brightness']}")
            print(f"   ‚Ä¢ ƒê·ªô t∆∞∆°ng ph·∫£n RMS: {brightness['contrast_rms']}")
            print(f"   ‚Ä¢ ƒê·ªô t∆∞∆°ng ph·∫£n Michelson: {brightness['michelson_contrast']}")
            print(f"   ‚Ä¢ Entropy: {brightness['entropy']}")
            
            # M√†u s·∫Øc
            color = analysis['color']
            print(f"\nüé® Ch·∫•t l∆∞·ª£ng m√†u s·∫Øc:")
            print(f"   ‚Ä¢ ƒê·ªô b√£o h√≤a TB: {color['saturation_mean']}")
            print(f"   ‚Ä¢ ƒê·ªô l·ªách chu·∫©n b√£o h√≤a: {color['saturation_std']}")
            print(f"   ‚Ä¢ ƒê·ªô r·ª±c r·ª°: {color['vibrance']}")
            print(f"   ‚Ä¢ ƒê·ªô l·ªách m√†u: {color['color_cast']}")
            print(f"   ‚Ä¢ S·ªë m√†u ƒë·ªôc nh·∫•t: {color['unique_colors']}")
            
            # Ph∆°i s√°ng
            exposure = analysis['exposure']
            print(f"\nüì∏ Ch·∫•t l∆∞·ª£ng ph∆°i s√°ng:")
            print(f"   ‚Ä¢ T·ª∑ l·ªá thi·∫øu s√°ng: {exposure['underexposed_ratio']:.2%}")
            print(f"   ‚Ä¢ T·ª∑ l·ªá qu√° s√°ng: {exposure['overexposed_ratio']:.2%}")
            print(f"   ‚Ä¢ T·ª∑ l·ªá ph∆°i s√°ng t·ªët: {exposure['well_exposed_ratio']:.2%}")
            print(f"   ‚Ä¢ D·∫£i ƒë·ªông: {exposure['dynamic_range']}")
            
            # B·ªë c·ª•c
            composition = analysis['composition']
            print(f"\nüñºÔ∏è Ch·∫•t l∆∞·ª£ng b·ªë c·ª•c:")
            print(f"   ‚Ä¢ C√¢n b·∫±ng b·ªë c·ª•c: {composition['composition_balance']:.3f}")
            print(f"   ‚Ä¢ M·∫≠t ƒë·ªô c·∫°nh: {composition['edge_density']:.6f}")
            print(f"   ‚Ä¢ T√≠nh ƒë·ªëi x·ª©ng: {composition['symmetry']:.3f}")
            
            # ƒê·ªô s√¢u tr∆∞·ªùng ·∫£nh
            dof = analysis['depth_of_field']
            print(f"\nüéØ ƒê·ªô s√¢u tr∆∞·ªùng ·∫£nh & Bokeh:")
            print(f"   ‚Ä¢ T·ª∑ l·ªá DOF: {dof['dof_ratio']}")
            print(f"   ‚Ä¢ Ch·∫•t l∆∞·ª£ng bokeh: {dof['bokeh_quality']}")
            print(f"   ‚Ä¢ Ph·∫ßn trƒÉm v√πng n√©t: {dof['focus_percentage']:.1f}%")
            if dof['estimated_aperture']:
                print(f"   ‚Ä¢ Kh·∫©u ƒë·ªô ∆∞·ªõc t√≠nh: {dof['estimated_aperture']}")
            print(f"   ‚Ä¢ ƒê·ªô n√©t trung t√¢m: {dof['center_sharpness']}")
            print(f"   ‚Ä¢ ƒê·ªô n√©t vi·ªÅn: {dof['edge_sharpness']}")
            
            # Khoa h·ªçc m√†u s·∫Øc
            color_sci = analysis['color_science']
            print(f"\nüî¨ Khoa h·ªçc m√†u s·∫Øc:")
            print(f"   ‚Ä¢ Nhi·ªát ƒë·ªô m√†u ∆∞·ªõc t√≠nh: {color_sci['estimated_color_temp']:.0f}K")
            print(f"   ‚Ä¢ Tint: {color_sci['tint']:.2f}")
            print(f"   ‚Ä¢ Shadows trung b√¨nh: {color_sci['shadows_avg']}")
            print(f"   ‚Ä¢ Midtones trung b√¨nh: {color_sci['midtones_avg']}")
            print(f"   ‚Ä¢ Highlights trung b√¨nh: {color_sci['highlights_avg']}")
            print(f"   ‚Ä¢ Lab A contrast: {color_sci['lab_a_contrast']}")
            print(f"   ‚Ä¢ Lab B contrast: {color_sci['lab_b_contrast']}")
            
            # Skin tone analysis
            skin = color_sci['skin_tone_quality']
            if skin['skin_percentage'] > 1:
                print(f"\nüë§ Ph√¢n t√≠ch skin tone:")
                print(f"   ‚Ä¢ Ph·∫ßn trƒÉm skin: {skin['skin_percentage']:.1f}%")
                print(f"   ‚Ä¢ T·ª± nhi√™n skin: {skin['skin_naturalness']:.1f}/100")
                print(f"   ‚Ä¢ Skin R/G/B: {skin['skin_r_avg']:.1f}/{skin['skin_g_avg']:.1f}/{skin['skin_b_avg']:.1f}")
            
            # Ch·ªâ s·ªë chuy√™n nghi·ªáp
            pro = analysis['professional_metrics']
            print(f"\nüîß Ch·ªâ s·ªë chuy√™n nghi·ªáp:")
            print(f"   ‚Ä¢ MTF ∆∞·ªõc t√≠nh: {pro['mtf_estimate']}")
            print(f"   ‚Ä¢ Chromatic Aberration: {pro['chromatic_aberration']:.2f}")
            print(f"   ‚Ä¢ Vignetting: {pro['vignetting']:.2f}%")
            print(f"   ‚Ä¢ Distortion: {pro['distortion_score']:.2f}¬∞")
            
            # Noise pattern
            noise_pattern = pro['noise_pattern']
            print(f"\nüé≠ Pattern nhi·ªÖu:")
            print(f"   ‚Ä¢ High freq noise: {noise_pattern['high_freq_noise']:.2f}")
            print(f"   ‚Ä¢ Banding score: {noise_pattern['banding_score']:.2f}")
            
            # ƒêi·ªÉm t·ªïng k·∫øt
            score = analysis['overall_score']
            print(f"\n‚≠ê ƒêI·ªÇM T·ªîNG K·∫æT:")
            print(f"   ‚Ä¢ ƒê·ªô s·∫Øc n√©t: {score['individual_scores']['sharpness']:.1f}/100")
            print(f"   ‚Ä¢ Ch·∫•t l∆∞·ª£ng t√≠n hi·ªáu: {score['individual_scores']['noise']:.1f}/100")
            print(f"   ‚Ä¢ T∆∞∆°ng ph·∫£n: {score['individual_scores']['contrast']:.1f}/100")
            print(f"   ‚Ä¢ M√†u s·∫Øc: {score['individual_scores']['color']:.1f}/100")
            print(f"   ‚Ä¢ Ph∆°i s√°ng: {score['individual_scores']['exposure']:.1f}/100")
            print(f"   ‚Ä¢ B·ªë c·ª•c: {score['individual_scores']['composition']:.1f}/100")
            print(f"   ‚Ä¢ ƒê·ªô s√¢u tr∆∞·ªùng ·∫£nh: {score['individual_scores']['depth_of_field']:.1f}/100")
            print(f"   ‚Ä¢ Khoa h·ªçc m√†u s·∫Øc: {score['individual_scores']['color_science']:.1f}/100")
            print(f"   ‚Ä¢ Chuy√™n nghi·ªáp: {score['individual_scores']['professional']:.1f}/100")
            print(f"\nüèÜ ƒêI·ªÇM T·ªîNG: {score['total_score']}/100 - {score['grade']}")
    
    def print_comparison_results(self, img1_path: str, analysis1: Dict, img2_path: str, analysis2: Dict):
        """In k·∫øt qu·∫£ so s√°nh gi·ªØa hai ·∫£nh"""
        print("\n" + "=" * 80)
        print("ü•ä K·∫æT QU·∫¢ SO S√ÅNH GI·ªÆA HAI ·∫¢NH")
        print("=" * 80)
        
        img1_name = os.path.basename(img1_path)
        img2_name = os.path.basename(img2_path)
        
        score1 = analysis1['overall_score']['total_score']
        score2 = analysis2['overall_score']['total_score']
        
        # So s√°nh t·ªïng th·ªÉ
        print(f"\nüèÜ ƒêI·ªÇM T·ªîNG K·∫æT:")
        print(f"   üì∏ {img1_name}: {score1}/100")
        print(f"   üì∏ {img2_name}: {score2}/100")
        
        if score1 > score2:
            winner = img1_name
            diff = score1 - score2
        elif score2 > score1:
            winner = img2_name  
            diff = score2 - score1
        else:
            winner = "H√≤a"
            diff = 0
        
        print(f"\nü•á NG∆Ø·ªúI TH·∫ÆNG: {winner}")
        if diff > 0:
            print(f"   üìä C√°ch bi·ªát: {diff:.1f} ƒëi·ªÉm")
        
        # So s√°nh chi ti·∫øt t·ª´ng ti√™u ch√≠
        print(f"\nüìä SO S√ÅNH CHI TI·∫æT:")
        
        categories = ['sharpness', 'noise', 'contrast', 'color', 'exposure', 'composition', 'depth_of_field', 'color_science', 'professional']
        category_names = ['ƒê·ªô s·∫Øc n√©t', 'Ch·∫•t l∆∞·ª£ng t√≠n hi·ªáu', 'T∆∞∆°ng ph·∫£n', 'M√†u s·∫Øc', 'Ph∆°i s√°ng', 'B·ªë c·ª•c', 'ƒê·ªô s√¢u tr∆∞·ªùng ·∫£nh', 'Khoa h·ªçc m√†u s·∫Øc', 'Chuy√™n nghi·ªáp']
        
        for cat, name in zip(categories, category_names):
            score1_cat = analysis1['overall_score']['individual_scores'][cat]
            score2_cat = analysis2['overall_score']['individual_scores'][cat]
            
            print(f"\n   üî∏ {name}:")
            print(f"      {img1_name}: {score1_cat:.1f}/100")
            print(f"      {img2_name}: {score2_cat:.1f}/100")
            
            if score1_cat > score2_cat:
                print(f"      ‚úÖ {img1_name} th·∫Øng (+{score1_cat - score2_cat:.1f})")
            elif score2_cat > score1_cat:
                print(f"      ‚úÖ {img2_name} th·∫Øng (+{score2_cat - score1_cat:.1f})")
            else:
                print(f"      ü§ù H√≤a")
        
        # Khuy·∫øn ngh·ªã
        print(f"\nüí° KHUY·∫æN NGH·ªä:")
        if diff > 10:
            print(f"   ‚Ä¢ ·∫¢nh {winner} c√≥ ch·∫•t l∆∞·ª£ng v∆∞·ª£t tr·ªôi h∆°n r√µ r·ªát")
        elif diff > 5:
            print(f"   ‚Ä¢ ·∫¢nh {winner} c√≥ ch·∫•t l∆∞·ª£ng t·ªët h∆°n ƒë√°ng k·ªÉ")
        elif diff > 0:
            print(f"   ‚Ä¢ ·∫¢nh {winner} c√≥ ch·∫•t l∆∞·ª£ng t·ªët h∆°n m·ªôt ch√∫t")
        else:
            print(f"   ‚Ä¢ Hai ·∫£nh c√≥ ch·∫•t l∆∞·ª£ng t∆∞∆°ng ƒë∆∞∆°ng nhau")
        
        # Ph√¢n t√≠ch ƒëi·ªÉm m·∫°nh/y·∫øu
        print(f"\nüìà PH√ÇN T√çCH ƒêI·ªÇM M·∫†NH/Y·∫æU:")
        
        for i, (name, analysis) in enumerate([(img1_name, analysis1), (img2_name, analysis2)], 1):
            scores = analysis['overall_score']['individual_scores']
            print(f"\n   üì∏ {name}:")
            
            # T√¨m ƒëi·ªÉm m·∫°nh nh·∫•t
            best_category = max(scores, key=scores.get)
            best_score = scores[best_category]
            best_name = dict(zip(categories, category_names))[best_category]
            
            # T√¨m ƒëi·ªÉm y·∫øu nh·∫•t
            worst_category = min(scores, key=scores.get)
            worst_score = scores[worst_category]
            worst_name = dict(zip(categories, category_names))[worst_category]
            
            print(f"      ‚úÖ ƒêi·ªÉm m·∫°nh: {best_name} ({best_score:.1f}/100)")
            print(f"      ‚ö†Ô∏è  ƒêi·ªÉm y·∫øu: {worst_name} ({worst_score:.1f}/100)")


def main():
    """H√†m ch√≠nh c·ªßa ch∆∞∆°ng tr√¨nh"""
    if len(sys.argv) != 3:
        print("C√°ch s·ª≠ d·ª•ng: python checkimg.py <ƒë∆∞·ªùng_d·∫´n_·∫£nh_1> <ƒë∆∞·ªùng_d·∫´n_·∫£nh_2>")
        print("V√≠ d·ª•: python checkimg.py image1.jpg image2.jpg")
        return
    
    image1_path = sys.argv[1]
    image2_path = sys.argv[2]
    
    # Ki·ªÉm tra file t·ªìn t·∫°i
    if not os.path.exists(image1_path):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh: {image1_path}")
        return
    
    if not os.path.exists(image2_path):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh: {image2_path}")
        return
    
    # Kh·ªüi t·∫°o analyzer v√† so s√°nh
    analyzer = ImageQualityAnalyzer()
    analyzer.compare_images(image1_path, image2_path)


if __name__ == "__main__":
    main()